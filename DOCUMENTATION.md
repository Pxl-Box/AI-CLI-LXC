# AI Terminal Workspace - Technical & User Documentation

## 1. System Architecture
The AI Terminal Workspace is a modern, web-based wrapper for local AI CLIs (like Gemini and Claude) and standard shell environments. It utilizes a client-server architecture powered by Node.js and WebSockets.

### Backend (Node.js/Express)
- **Core Server (`server.js`):** Manages HTTP requests, static file serving, and WebSocket connections via `Socket.io`.
- **PTY Management (`node-pty`):** Spawns and manages pseudo-terminal processes on the host machine. These processes are mapped to unique Tab IDs on the frontend.
- **File System API:** Custom hooks for directory listing, file reading, folder creation, and multipart file uploads (via `multer`).
- **Persistence Layer:** 
    - **PTY Session Persistence:** PTY processes are stored in a global Map outside the connection scope, allowing them to survive accidental socket disconnections or page refreshes.
    - **Black Box Recovery:** Automatically logs internal AI state to `.gemini_recovery.json` to allow LLM sessions to resume after OOM crashes.

### Frontend (Vanilla JS/CSS)
- **Terminal Emulator (`xterm.js`):** Provides a high-performance terminal UI with support for themes, resizing, and web links.
- **UI Components:**
    - **Sidebar:** Accordion-style navigation for launchers, local models (Ollama), and custom agents.
    - **Workspace Explorer:** An interactive modal for browsing files, "Mentioning" assets to AI, and previewing code.
    - **System Pulse:** Real-time hardware monitor (CPU/RAM) using the `systeminformation` library on the backend.

---

## 2. File Structure & Data Storage

### Directory Layout
```text
/workspaces/Gemini/AI-CLI-LXC/
├── server.js               # Main entry point (Backend logic)
├── package.json            # Dependencies and scripts
├── .gemini_recovery.json   # Auto-generated "Black Box" recovery log
├── GEMINI.md               # Persistent project memory and mandates
├── agents/                 # JSON storage for custom AI personas
├── public/                 # Frontend assets
│   ├── index.html          # UI Structure
│   ├── main.js             # Frontend logic & Socket handlers
│   └── style.css           # Custom glassmorphism styling
├── Screenshots/            # Visual history of development
└── install scripts         # proxmox-create-lxc.sh, setup-lxc.sh, etc.
```

### Data Handling
- **File Uploads:** Files are stored in a `workspace-uploads/` subfolder within the currently selected workspace.
- **AI Agents:** Custom personas are stored as standalone `.json` files in the `agents/` directory. Each file contains the name, model, and system prompt.
- **Browser Storage:** `localStorage` is used to persist:
    - Assigned paths for Gemini/Claude workspaces.
    - Saved project bookmarks.
    - Terminal tab state (IDs and titles) for session restoration.

---

## 3. Key Features & Workflow

### Multi-Tab Terminal
Users can open multiple terminals (Standard Shell, Gemini, Claude, or Ollama) using the **+** icon. Each tab is isolated and maintains its own history.

### Dual-Terminal Split View
Click the **Split Screen** icon in the terminal header to pin two tabs side-by-side. 
- The "Active" tab stays on the left.
- Any other selected tab moves to the right.
- Useful for comparing code generated by Gemini and Claude simultaneously.

### Workspace Explorer ("The Folder Icon")
The explorer is the bridge between your file system and the AI.
- **Peek:** Preview file contents with syntax highlighting (Prism.js) without opening them in a terminal.
- **Mention:** Sends the filename to the active terminal formatted for AI processing (e.g., `Attached files: "config.js"`).
- **Multi-select:** Use checkboxes to mention multiple files at once.
- **Gather Context:** A power-user button that automatically finds and mentions architectural files (GEMINI.md, package.json, etc.).

### Session Persistence & Recovery
- **Page Refresh:** If you refresh the browser, the workspace will automatically re-open your tabs and re-attach to the running terminal processes.
- **AI Recovery:** If the CLI crashes (OOM error), starting a new session and saying "Resume" allows the AI to read `.gemini_recovery.json` and pick up where it left off.

---

## 4. Expected Usage

### For Developers
1. **Focus Workspaces:** Use the Settings gear to assign Gemini to your frontend folder and Claude to your backend folder.
2. **Launch AI:** Click the respective buttons to automatically `cd` and launch the CLI in those folders.
3. **Commit Memory:** Click the **Floppy Disk** icon periodically to tell the AI to summarize progress in `GEMINI.md`.

### For Local LLM Users
1. **Sync Models:** The Ollama dropdown automatically syncs with your installed models.
2. **Run Local:** Select a model (e.g., DeepSeek R1) and click **Run** to launch a local chat session.
3. **System Pulse:** Keep an eye on the header to ensure your local models aren't exhausting the container's RAM.

---

## 5. Deployment
The system is designed to be deployed as a **Proxmox LXC**.
- Use `proxmox-create-lxc.sh` on the host for 1-click setup.
- The web interface defaults to port **3000**.
- Services are managed by `PM2` for automatic restarts on system reboot.
